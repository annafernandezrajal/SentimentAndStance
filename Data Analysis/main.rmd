##Testing R

Load libraries
```{r}
library(gplots)
library(ggplot2)
library(gridExtra)
library(grid)
library(likert)
library(ggnewscale)
library(caret)
library(pals)
library(yardstick)
```

Load data
```{r}
data <- read.csv("C:/Users/steem/Desktop/StudiesKTH/II2202 Research Methodology and Scientific Writing/SentimentAndStance/Data Analysis/dataset/output_test_classification.csv")
data_reg <- read.csv("C:/Users/steem/Desktop/StudiesKTH/II2202 Research Methodology and Scientific Writing/SentimentAndStance/Data Analysis/dataset/output_test_regression.csv")

##data <- read.csv("C:/Users/steem/Desktop/StudiesKTH/II2202 Research Methodology and Scientific Writing/SentimentAndStance/Data Analysis/dataset/output.csv")

data
```

Pre-process
```{r}
stance <- data$Stance
sentiment <- data$Sentiment
predicted_sentiment <- data_reg$sentimentVader
predicted_stance <- data$StanceSVM

stance <- replace(stance, stance == "FAVOR", 1)
stance <- replace(stance, stance == "NONE", 0)
stance <- replace(stance, stance == "AGAINST", -1)
stance <- as.numeric(stance)

sentiment <- replace(sentiment, sentiment == "neg", -1)
sentiment <- replace(sentiment, sentiment == "other", 0)
sentiment <- replace(sentiment, sentiment == "pos", 1)
sentiment <- as.numeric(sentiment)

predicted_sentiment <- replace(predicted_sentiment, predicted_sentiment < 0, -1)
predicted_sentiment <- replace(predicted_sentiment, predicted_sentiment > 0, 1)
predicted_sentiment <- as.numeric(predicted_sentiment)
# predicted_sentiment <- replace(predicted_sentiment, predicted_sentiment == "neg", -1)
# predicted_sentiment <- replace(predicted_sentiment, predicted_sentiment == "other", 0)
# predicted_sentiment <- replace(predicted_sentiment, predicted_sentiment == "pos", 1)
# predicted_sentiment <- as.numeric(predicted_sentiment)

predicted_stance <- replace(predicted_stance, predicted_stance == "FAVOR", 1)
predicted_stance <- replace(predicted_stance, predicted_stance == "NONE", 0)
predicted_stance <- replace(predicted_stance, predicted_stance == "AGAINST", -1)
predicted_stance <- as.numeric(predicted_stance)

data$Stance <- stance
data$Sentiment <- sentiment
data$sentimentVader <- predicted_sentiment
data$StanceSVM <- predicted_stance
```

Visualization
```{r}
# Based on DanO's answer on https://stackoverflow.com/questions/61504970/ggplot2-heatmap-2-different-color-schemes-confusion-matrix-matches-in-differe but with several fixes and improvements
plot.plotWithDiagonalMarked <- function(confusionMatrix, xlabel, ylabel, xValueLabels, yValueLabels, valueOrdering) {
  yValueLabels = rev(yValueLabels) #y labels go from bottom to top, instead of the expected top to bottom

  confusionMatrix_diagonalMarked <- as.data.frame(confusionMatrix$table)
  confusionMatrix_diagonalMarked$diag <- confusionMatrix_diagonalMarked$Prediction == confusionMatrix_diagonalMarked$Reference # Get the diagonal
  # confusionMatrix_diagonalMarked[confusionMatrix_diagonalMarked$Freq == 0, ] <- NA # If an tile is empty, mark it is NA so we can give it another color (comma is there to prevent a weird crash https://stackoverflow.com/questions/51027983/r-error-from-nas-to-0-duplicate-subscripts-for-column-in-data-frame)
  confusionMatrix_diagonalMarked$Reference <- reverse.levels(confusionMatrix_diagonalMarked$Reference) # diagonal starts at top left
  confusionMatrix_diagonalMarked$ref_freq <- confusionMatrix_diagonalMarked$Freq * ifelse(confusionMatrix_diagonalMarked$diag, 1, -1) # flip sign for non-diagonal values
  # confusionMatrix_diagonalMarked$ref_freq <- scale(confusionMatrix_diagonalMarked$ref_freq) # normalize values
  confusionMatrix_diagonalMarked$ref_freq <- confusionMatrix_diagonalMarked$ref_freq + max(confusionMatrix_diagonalMarked$Freq) + min(confusionMatrix_diagonalMarked$Freq)  # This for some reason fixes the colour range not being scaled properly, found by experimentation

  print(confusionMatrix_diagonalMarked)

  # plotting the matrix
  confusionMatrix_diagonalMarked_plot <- ggplot(
            data = confusionMatrix_diagonalMarked,
            aes(x = Prediction, y = Reference, fill = Freq)) +
          xlab(xlabel) +
          ylab(ylabel) +
          geom_tile(
            data = confusionMatrix_diagonalMarked,
            aes(fill = ref_freq)) +
          scale_fill_gradientn(
             guide = FALSE,
             colours=c("red", "white", "#D6EAF8", "#2E86C1"),
             values=scales::rescale(c(-1, 0, 0.001, 1)),
             na.value="white") +
          geom_text(
             aes(label = Freq),
             color = 'black',
             size = 6) +
          scale_x_discrete(labels=xValueLabels, limits=valueOrdering, expand=c(0,0), position = "top") +
          scale_y_discrete(labels=yValueLabels, limits=rev(valueOrdering), expand=c(0,0)) +
          coord_equal() +
          theme_light() +
          theme(
            panel.grid.major = element_blank(),
            panel.grid.minor = element_blank(),
            legend.position = "none",
            panel.border = element_blank(),
            plot.background = element_blank(),
            axis.line = element_blank(),
            axis.text = element_text(size=20),
            axis.title= element_text(size=30, face="bold")
            )
  return(confusionMatrix_diagonalMarked_plot)
}
```

```{r}
sentimentValueLabels = c("Negative", "Neutral", "Positive")
stanceValueLabels = c("Against", "Neutral", "Agree")
valueOrdering = c("-1", "0", "1")
```

EXPERIMENTS

Experiment 1) How does sentiment analysis perform compared to the ground-truth?
```{r}
cat(sum(sentiment == predicted_sentiment) / length(sentiment), "% accuracy", sep = '')

vader_ground <- data.frame(
  Prediction = data$sentimentVader,
  Reference = data$Sentiment
)

vader_ground$Reference <- as.factor(vader_ground$Reference)
vader_ground$Prediction <- as.factor(vader_ground$Prediction)

confusionMatrix1 <- caret::confusionMatrix(vader_ground$Prediction, vader_ground$Reference)
plot <- plot.plotWithDiagonalMarked(confusionMatrix1, 'VADER sentiment', 'Actual sentiment', sentimentValueLabels, sentimentValueLabels, valueOrdering)
plot
ggsave("C:/Users/steem/Desktop/StudiesKTH/II2202 Research Methodology and Scientific Writing/SentimentAndStance/Data Analysis/images/VaderGroundTruthHeatmap.png")
```

VADER FITTED
```{r}
bias_term_vader = 0
neutral_range_vader = 0

bias_term_values <- seq(-.85, .85, by=0.1)
neutral_range_values <- seq(0.01, .9, by=0.1)

best_accuracy = 0

for(test_range_vader in neutral_range_values){
  for(test_bias_term_vader in bias_term_values){
    predicted_sentiment_fitted = data_reg$sentimentVader

    # cat(test_bias_term_vader - neutral_range/2, " ", bias_term_vader + neutral_range/2,"\n")

    predicted_sentiment_fitted <- replace(predicted_sentiment_fitted, predicted_sentiment_fitted < test_bias_term_vader - test_range_vader/2, -1)
    predicted_sentiment_fitted <- replace(predicted_sentiment_fitted, predicted_sentiment_fitted > test_bias_term_vader + test_range_vader/2, 1)
    predicted_sentiment_fitted <- replace(predicted_sentiment_fitted,
                                          predicted_sentiment_fitted > test_bias_term_vader - test_range_vader/2 &
                                                  predicted_sentiment_fitted < test_bias_term_vader + test_range_vader/2,
                                          0)
    predicted_sentiment_fitted <- as.numeric(predicted_sentiment_fitted)

    accuracy = sum(sentiment == predicted_sentiment_fitted) / length(sentiment)

    if(accuracy > best_accuracy){
      best_accuracy = accuracy
      bias_term_vader = test_bias_term_vader
      neutral_range_vader = test_range_vader
    }

    cat(sum(sentiment == predicted_sentiment_fitted) / length(sentiment), "% accuracy \n", sep = '')
  }
}

# Use best value found
predicted_sentiment_fitted <- replace(predicted_sentiment_fitted, predicted_sentiment_fitted < bias_term_vader - neutral_range_vader/2, -1)
predicted_sentiment_fitted <- replace(predicted_sentiment_fitted, predicted_sentiment_fitted > bias_term_vader + neutral_range_vader/2, 1)
predicted_sentiment_fitted <- replace(predicted_sentiment_fitted,
                                      predicted_sentiment_fitted > bias_term_vader - neutral_range_vader/2 &
                                              predicted_sentiment_fitted < bias_term_vader + neutral_range_vader/2,
                                      0)
predicted_sentiment_fitted <- as.numeric(predicted_sentiment_fitted)

cat(sum(sentiment == predicted_sentiment_fitted) / length(sentiment), "% accuracy, bias ", bias_term_vader, " neutral range: ", neutral_range_vader, "\n", sep = '')


vader_ground <- data.frame(
        Prediction = predicted_sentiment_fitted,
        Reference = data$Sentiment
)

vader_ground$Reference <- as.factor(vader_ground$Reference)
vader_ground$Prediction <- as.factor(vader_ground$Prediction)

confusionMatrix1 <- caret::confusionMatrix(vader_ground$Prediction, vader_ground$Reference)
plot <- plot.plotWithDiagonalMarked(confusionMatrix1, 'VADER fitted sentiment', 'Actual sentiment', sentimentValueLabels, sentimentValueLabels, valueOrdering)
plot
ggsave("C:/Users/steem/Desktop/StudiesKTH/II2202 Research Methodology and Scientific Writing/SentimentAndStance/Data Analysis/images/VaderFittedGroundTruthHeatmap.png")
```

Experiment 2) How does stance detection perform compared to the ground-truth?
```{r}
cat(sum(stance == predicted_stance) / length(stance),  "% accuracy", sep = '')

stance_ground <- data.frame(
  Prediction = data$StanceSVM,
  Reference = data$Stance
)

stance_ground$Reference <- as.factor(stance_ground$Reference)
stance_ground$Prediction <- as.factor(stance_ground$Prediction)

confusionMatrix2 <- caret::confusionMatrix(stance_ground$Prediction, stance_ground$Reference)

plot <- plot.plotWithDiagonalMarked(confusionMatrix2, 'SVM stance', 'Actual stance', stanceValueLabels, stanceValueLabels, valueOrdering)
plot
ggsave("images/StanceSVMGroundTruthHeatmap.png")
```

Experiment 3) How much overlap is there between ground-truth sentiment and stance?
```{r}
cat(sum(stance == sentiment) / length(stance), "% overlap", sep = '')

ground_sentiment_stance <- data.frame(
  Prediction = data$Sentiment,
  Reference = data$Stance
)

ground_sentiment_stance$Prediction <- as.factor(ground_sentiment_stance$Prediction)
ground_sentiment_stance$Reference <- as.factor(ground_sentiment_stance$Reference)

confusionMatrix3 <- caret::confusionMatrix(ground_sentiment_stance$Reference, ground_sentiment_stance$Prediction)

plot <- plot.plotWithDiagonalMarked(confusionMatrix3, 'Actual sentiment', 'Actual stance', sentimentValueLabels, stanceValueLabels, valueOrdering)
plot
ggsave("images/GroundTruthSentimentStance.png")
```

Experiment 4) How much overlap is there between sentiment and stance?

```{r}
cat(sum(predicted_stance == predicted_sentiment) / length(predicted_stance),  "% accuracy", sep = '')

pred_sent_stance <- data.frame(
  Prediction = data$StanceSVM,
  Reference = data$sentimentVader
)

pred_sent_stance$Reference <- as.factor(pred_sent_stance$Reference)
pred_sent_stance$Prediction <- as.factor(pred_sent_stance$Prediction)

confusionMatrix4 <- caret::confusionMatrix(pred_sent_stance$Reference, pred_sent_stance$Prediction)

plot <- plot.plotWithDiagonalMarked(confusionMatrix4, 'VADER sentiment', 'SVM Stance', sentimentValueLabels, stanceValueLabels, valueOrdering)
plot
ggsave("images/PredictionSentimentStance.png")
```

Experiment 5) How do values for sentiment map to values for stance (with bucket sizes of 0.2)?






